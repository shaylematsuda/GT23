---
title: "Data_wrangle"
author: "Shayle Matsuda"
date: "2025-11-20"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Library load
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(plyr) 
library(dplyr)
library(ggplot2)
library(ggpubr)
library(lmerTest)
library(car)
library(emmeans)
library(gridExtra)
library(multcomp)
library(reshape)
library(factoextra)
library(reshape2)
library(vegan) 
library(pairwiseAdonis)
library("scales")
packageVersion("scales")
library(RColorBrewer)
library(colorRamps)
library(devtools)
library(phyloseq)
library(readr)
library(vegan)
library(ape)
library(geosphere)
library(ade4)
library(microbiome)  
library(knitr)
library(parzer)#parzer package to deal with coordinates
library(dplyr)
library(stringr)
```

Build phyloseq object for initial QC
```{r}
#Sam####
md<-read.csv("df_final.csv")
md<-md[,-1]

miseq<-read.csv("GT23_Miseq_SampleIDs.csv")
miseq$Tube<-miseq$Sample_ID
miseq$Tube <- sub("dup$", "", miseq$Tube)

#figure out dup md 
Issue<- md %>%
  dplyr::count(Tube) %>%
  filter(n > 1)
#write.csv(Issue, "Issue.csv") 

#Fix duplicates (most samples duplicated dates -not real-, confirmed on written datesheets )
tubes_to_remove <- c(
  1454,1456,1458,1459,1464,1465,1467,1468,1469,1470,
  1471,1472,1473,1475,1478,1480,1481,1483,1486,1487,
  1488,1489,1490,1491,1492
)
md <- md %>%
  filter(!(Tube %in% tubes_to_remove & Date == "5/22/23"))
#issue with Tube 1046, remove tube when Tank.datasheet is HI_Control_2 which was removed from experiment
md <- md %>%
  filter(!(Tube == 1046 & Tank.datasheet == "HI_Control_2"))
#issue with Tube 436. frag 92 (acer) tube 436 was written on data sheet. But it was not erased from 1291-8 (pcomp). for NOW keep frag 92 but check NMDS to confirm species. potentially trash. 
md <- md %>%
  filter(!(Tube == 436 & Tank.datasheet == "HI_Control_2"))

# now merge:
miseq_merged <- miseq %>%
  left_join(md, by = "Tube")

#update Type for Mock, Blanks
miseq_merged <- miseq_merged %>%
  mutate(
    Type = case_when(
      str_detect(Tube, regex("Blank", ignore_case = TRUE)) ~ "Blank",
      str_detect(Tube, regex("DNA",   ignore_case = TRUE)) ~ "Blank",
      str_detect(Tube, regex("MOCK",  ignore_case = TRUE)) ~ "Mock",
      TRUE ~ Type
    )
  )

#for phyloseq
sam0<-miseq_merged
sam1 <- as.matrix(sam0)
rownames(sam1) <- sam0$Sample_ID
sam <- sample_data(data.frame(sam1))



# OTU Table ####
OTU<-read.table("16S-pipeline_outputs_not subset/Results/main/details/abundance_table_100.shared.txt", sep='', header=T)

OTU <- OTU %>%
  mutate(Group = gsub("_", ".", Group)) %>%
  mutate(Group = gsub("S\\d{3}\\.L001", "", Group)) %>%
    mutate(Group = gsub("S\\d{2}\\.L001", "", Group)) %>%
  mutate(Group = gsub("\\.$", "", Group))

otu1 <- as.matrix(OTU[, -c(1,3)]) # remove first col "label"
otu2.df<-as.data.frame(otu1) #make df copy to make samp names as row names in matrix
rownames(otu2.df) <- otu2.df$Group
otu3 <- as.matrix(otu2.df[, -(1)]) # remove first col samplename
storage.mode(otu3) <- "numeric"
otu <- phyloseq::otu_table(otu3, taxa_are_rows = FALSE)

#Taxonomy Table ####
#tax table annotations_100_taxonomy.csv (edited to be in proper format with proper col names in excel (remove ";"))

#taxonomy:
TAX<- read.csv("16S-pipeline_outputs_not subset/Results/main/details/annotations_100.taxonomy.csv", colClasses = "character") 
tax1 <- as.matrix(TAX[, -1], dimnames = list(TAX$OTU, colnames(TAX[-1])))
rownames(tax1) <- TAX$OTU
tax <- tax_table(tax1)

# Read the data into phyloseq ####
Bac.seq = phyloseq(otu, tax,sam) 
Bac.seq

#load your tre file FastTree_100.nwk
treefile<- read.tree("16S-pipeline_outputs_not subset/Results/postprocessing/unifrac/FastTree_100.nwk")
phy_tree(Bac.seq) <- treefile
Bac.seq

#Save before QC if needed
#save(Bac.seq, file = "RData/Bac.seq.RData")

# 
# # Check sample names for the OTU table
# otu_names <- rownames(otu) 
# 
# # Check sample names for the sample data
# sam_names <- rownames(sam)
# 
# # Check taxonomy table row names (these are typically OTU IDs, not sample names)
# tax_ids <- rownames(tax) 
# 
# # Compare them
# print(paste("Number of samples in OTU table:", length(otu_names)))
# print(paste("Number of samples in Sample Data:", length(sam_names)))
# 
# # Find the differences
# # Samples in OTU that are missing in SAM
# missing_in_sam <- setdiff(otu_names, sam_names)
# print(paste("Samples in OTU but not in SAM:", toString(missing_in_sam)))
# 
# # Samples in SAM that are missing in OTU
# missing_in_otu <- setdiff(sam_names, otu_names)
# print(paste("Samples in SAM but not in OTU:", toString(missing_in_otu)))
# 

#look at dups
sd <- as(sample_data(Bac.seq), "data.frame")
## 2. Find duplicated Sample_IDs
dup_ids <- sd$Tube[duplicated(sd$Tube)]
dup_ids <- unique(dup_ids)  # keep each duplicated ID once

dup_ids
# This shows which Sample_IDs have duplicates

## (Optional) Inspect the duplicated samples in the metadata
sd_dups <- sd %>% 
  filter(Tube %in% dup_ids)

sd_dups

## 3. Subset the phyloseq object to only duplicated samples
ps_dups <- subset_samples(Bac.seq, Tube %in% dup_ids)

ps_dups

seq_counts <- sample_sums(ps_dups)

seq_counts #most will get filtered out (1174, 1194, 1218, 538)

# Agglomerate at a taxonomic rank (change "Family" if needed)
ps_dups_fam <- tax_glom(ps_dups, taxrank = "Family")

# Transform to relative abundance
ps_dups_fam_rel <- transform_sample_counts(ps_dups_fam, function(x) x / sum(x))

# Melt to long format
df_plot <- psmelt(ps_dups_fam_rel)

# If Sample_ID is your x-axis grouping variable:
ggplot(df_plot, aes(x = Sample_ID, y = Abundance, fill = Family)) +
  geom_bar(stat = "identity") +
  labs(x = "Sample", y = "Relative Abundance", title = "Duplicated Samples") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
    panel.spacing = unit(1, "lines")
  )

#Tube 480 both are similar, Tube 436dup looks uncharictaristically different, cut.  
```

QC:
```{r}
## check out data
ntaxa(Bac.seq)  #num taxa
nsamples(Bac.seq)   #num samples
sample_names(Bac.seq) #samp names
rank_names(Bac.seq) 
sample_variables(Bac.seq) # metadata cats
sums<-sample_sums(Bac.seq)
sums<-as.data.frame(sums)
#write.csv(sums, "sums.csv")

# create df of sample data to view 
sample.data <- as(sample_data(Bac.seq), "data.frame") #create sample data frame to view
sample.data$LibrarySize <- sample_sums(Bac.seq)
sample.data <- sample.data[order(sample.data$LibrarySize),]
sample.data$Index <- seq(nrow(sample.data))  
ggplot(data = sample.data, aes(x=Index, y=LibrarySize, color = species.x)) +
  geom_point()

ggplot(data = sample.data, aes(x=Index, y=LibrarySize, color = species.x)) +
  geom_point()+
  facet_wrap(~species.x)

richness(Bac.seq)
plot_richness(Bac.seq, measures = c("Observed","Shannon"), color="species.x") 
evenness(Bac.seq)

#NTC (all NTC subsampled out due to low reads)
NTCs<-subset_samples(Bac.seq, Tube=="Blank")
TopNOTUsNTC = names(sort(taxa_sums(NTCs), TRUE)[1:200])
bac50 = prune_taxa(TopNOTUsNTC, NTCs)
bacBarPlot<-plot_bar(bac50,  fill="Phylum");bacBarPlot #all low

richness(NTCs)
plot_richness(NTCs, measures = c("Observed","Shannon"))
evenness(NTCs)

#Mock
Mock<-subset_samples(Bac.seq, Type=="Mock")
TopNOTUsMock = names(sort(taxa_sums(Mock), TRUE)[1:200])
bac50 = prune_taxa(TopNOTUsMock, Mock)
bacBarPlot<-plot_bar(bac50,  fill="Phylum");bacBarPlot

richness(Mock)
plot_richness(Mock, measures = c("Observed","Shannon"))
evenness(Mock)

## how many samples am i going to lose
reads_per_sample <- data.frame(
  Sample = sample_names(Bac.seq),
  Reads  = sample_sums(Bac.seq)
)

meta <- as(sample_data(Bac.seq), "data.frame")
meta$Sample <- rownames(meta)

reads_df <- left_join(reads_per_sample, meta, by = "Sample")

lost_counts2 <- reads_df %>%
  group_by(species.x) %>%
  dplyr::summarise(
    total_samples = n(),
    samples_below_2000 = sum(Reads < 2000),
    samples_above_2000 = sum(Reads >= 2000)
  )

### Rerun doing subsampling at 3000 for ACER
# Mcap is pretty bad. a 2k subset would only leave 91, and 3k 77

sample.data.mcap<-subset(sample.data, species.x=="Mcap")
write.csv(sample.data.mcap, "sample.data.mcap.csv")
```

## START HERE for ACER subset to 3000
```{r}
#Sam####

#for phyloseq use sam
sam

# OTU Table ####
OTU<-read.table("3k_16S-pipeline_outputs/Results/main/details/abundance_table_100.shared.txt", sep='', header=T)

OTU <- OTU %>%
  mutate(Group = gsub("_", ".", Group)) %>%
  mutate(Group = gsub("S\\d{3}\\.L001", "", Group)) %>%
    mutate(Group = gsub("S\\d{2}\\.L001", "", Group)) %>%
  mutate(Group = gsub("\\.$", "", Group))

otu1 <- as.matrix(OTU[, -c(1,3)]) # remove first col "label"
otu2.df<-as.data.frame(otu1) #make df copy to make samp names as row names in matrix
rownames(otu2.df) <- otu2.df$Group
otu3 <- as.matrix(otu2.df[, -(1)]) # remove first col samplename
storage.mode(otu3) <- "numeric"
otu <- phyloseq::otu_table(otu3, taxa_are_rows = FALSE)

#Taxonomy Table ####
#tax table annotations_100_taxonomy.csv (edited to be in proper format with proper col names in excel (remove ";"))

#taxonomy:
TAX<- read.csv("3k_16S-pipeline_outputs/Results/main/details/annotations_100.taxonomy.csv", colClasses = "character") 
tax1 <- as.matrix(TAX[, -1], dimnames = list(TAX$OTU, colnames(TAX[-1])))
rownames(tax1) <- TAX$OTU
tax <- tax_table(tax1)

# Read the data into phyloseq
Bac.seq = phyloseq(otu, tax,sam) 
Bac.seq

#load your tre file FastTree_100.nwk
treefile<- read.tree("3k_16S-pipeline_outputs/Results/postprocessing/unifrac/FastTree_100.nwk")
phy_tree(Bac.seq) <- treefile
Bac.seq



```
Examine dups
```{r}
sd <- as(sample_data(Bac.seq), "data.frame")
## 2. Find duplicated Sample_IDs
dup_ids <- sd$Tube[duplicated(sd$Tube)]
dup_ids <- unique(dup_ids)  # keep each duplicated ID once

dup_ids
# This shows which Sample_IDs have duplicates

## (Optional) Inspect the duplicated samples in the metadata
sd_dups <- sd %>% 
  filter(Tube %in% dup_ids)

sd_dups

## 3. Subset the phyloseq object to only duplicated samples
ps_dups <- subset_samples(Bac.seq, Tube %in% dup_ids)

ps_dups

seq_counts <- sample_sums(ps_dups)

seq_counts

# Agglomerate at a taxonomic rank (change "Family" if needed)
ps_dups_fam <- tax_glom(ps_dups, taxrank = "Family")

# Transform to relative abundance
ps_dups_fam_rel <- transform_sample_counts(ps_dups_fam, function(x) x / sum(x))

# Melt to long format
df_plot <- psmelt(ps_dups_fam_rel)

# If Sample_ID is your x-axis grouping variable:
ggplot(df_plot, aes(x = Sample_ID, y = Abundance, fill = Family)) +
  geom_bar(stat = "identity") +
  labs(x = "Sample", y = "Relative Abundance", title = "Duplicated Samples") +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
    panel.spacing = unit(1, "lines")
  )

#Tube 480 both are similar, Tube 436dup looks wonky, drop 

Bac.seq<-subset_samples(Bac.seq, Sample_ID!="436dup")
Bac.seq<-subset_samples(Bac.seq, Sample_ID!="480dup")
Bac.seq
```
Save file
```{r}
#Save before QC if needed
save(Bac.seq, file = "RData/Bac.3k.RData")
```

